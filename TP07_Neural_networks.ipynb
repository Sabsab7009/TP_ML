{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2CSSID-TP07. Réseaux de neurones\n",
    "\n",
    "Dans ce TP, nous allons voir les réseaux de neurones.\n",
    "Premierement, nous allons implémenter la rétro-propagation, une fonction d'activation et une fonction du cout.\n",
    "Ensuite, nous allons tester l'effet de l'initialisation des paramètres, les fonctions d'activation, ainsi que les fonctions d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binômes : \n",
    "- **Binôme 1 :** Chouikrat Sabrina. \n",
    "- **Binôme 2 :** Karim Meryem Batoul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Voici un exemple d'un reseau de neurones :\n",
    "\n",
    "![exemple](D:\\Documents\\2CSSID\\myyear\\S1\\ML\\TP07SID\\RNPA-exp.png)\n",
    "\n",
    "---\n",
    "\n",
    "**Afin de mettre à jour** $w_{11}^{(4)}$\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(4)}} = \\overbrace{\\frac{\\partial J}{\\partial f_{1}^{(4)}} \\frac{\\partial f_{1}^{(4)}}{\\partial z_{1}^{(4)}}}^{\\delta_{1}^{(4)}} \\overbrace{\\frac{\\partial z_{1}^{(4)}}{\\partial w_{11}^{(4)}}}^{a_{1}^{(3)}}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial f_{1}^{(4)}} = \\frac{(0.840, 0.843) - (0, 1)}{(0.840, 0.843) - (0.840, 0.843)^2} \n",
    "= (6.25, -1.186)$$\n",
    "\n",
    "$$\\frac{\\partial f_{1}^{(4)}}{\\partial z_{1}^{(4)}} = (0.840, 0.843) (0.160, 0.157) = (0.134, 0.132)$$\n",
    "\n",
    "$$\\delta_{1}^{(4)} = (6.25, -1.186) (0.134, 0.132) \\approx (0.838, -0.157)$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(4)}} = moy((0.838, -0.157) (0.555, 0.612)) \n",
    "\\approx moy(0.465, -0.096) = 0.184$$\n",
    "\n",
    "---\n",
    "\n",
    "**Afin de mettre à jour** $w_{21}^{(4)}$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{21}^{(4)}} = \\overbrace{\\frac{\\partial J}{\\partial f_{1}^{(4)}} \\frac{\\partial f_{1}^{(4)}}{\\partial z_{1}^{(4)}}}^{\\delta_{1}^{(4)}} \\overbrace{\\frac{\\partial z_{1}^{(4)}}{\\partial w_{21}^{(4)}}}^{a_{2}^{(3)}}$$\n",
    "\n",
    "$$\\delta_{1}^{(4)} = (0.838, -0.157)$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{21}^{(4)}} = moy((0.838, -0.157) (0.386, 0.360)) \n",
    "\\approx moy(0.323, -0.056) = 0.134$$\n",
    "\n",
    "---\n",
    "\n",
    "**Afin de mettre à jour** $w_{11}^{(3)}$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(3)}} = \n",
    "\\overbrace{\n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial J}{\\partial f_{1}^{(4)}} \n",
    "\t\t\\frac{\\partial f_{1}^{(4)}}{\\partial z_{1}^{(4)}}\n",
    "\t}^{\\delta_{1}^{(4)}} \n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial z_{1}^{(4)}}{\\partial f_{1}^{(3)}}\n",
    "\t}^{w_{11}^{(4)}} \n",
    "\t\\frac{\\partial f_{1}^{(3)}}{\\partial z_{1}^{(3)}} \n",
    "}^{\\delta_{1}^{(3)}} \n",
    "\\overbrace{\n",
    "\t\\frac{\\partial z_{1}^{(3)}}{\\partial w_{11}^{(3)}}\n",
    "}^{a_{1}^{(2)}}\n",
    "\\text{ Ici, on utilise l'ancien } w_{11}^{(4)}$$\n",
    "\n",
    "$$\\frac{\\partial f_{1}^{(3)}}{\\partial z_{1}^{(3)}} \\approx \n",
    "(0.555, 0.612) (0.445, 0.388) = (0.247, 0.237)$$\n",
    "\n",
    "$$\\delta_{1}^{(3)} = (0.838, -0.157) * 0.7 * (0.247, 0.237) \\approx (0.145, -0.026)$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(2)}} = moy((0.145, -0.026) (0.622, 0.900)) \n",
    "= moy(0.090, -0.023) = 0.033$$\n",
    "\n",
    "---\n",
    "\n",
    "**Afin de mettre à jour** $w_{12}^{(3)}$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{12}^{(3)}} = \n",
    "\\overbrace{\n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial J}{\\partial f_{1}^{(4)}} \n",
    "\t\t\\frac{\\partial f_{1}^{(4)}}{\\partial z_{1}^{(4)}}\n",
    "\t}^{\\delta_{1}^{(4)}} \n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial z_{1}^{(4)}}{\\partial f_{2}^{(3)}}\n",
    "\t}^{w_{11}^{(4)}} \n",
    "\t\\frac{\\partial f_{2}^{(3)}}{\\partial z_{2}^{(3)}} \n",
    "}^{\\delta_{2}^{(3)}} \n",
    "\\overbrace{\n",
    "\t\\frac{\\partial z_{2}^{(3)}}{\\partial w_{12}^{(3)}}\n",
    "}^{a_{1}^{(2)}}\n",
    "\\text{ Ici, on utilise l'ancien } w_{12}^{(4)}$$\n",
    "\n",
    "$$\\frac{\\partial f_{2}^{(3)}}{\\partial z_{2}^{(3)}} \\approx \n",
    "(0.386, 0.360) (0.614, 0.64) = (0.237, 0.230)$$\n",
    "\n",
    "$$\\delta_{2}^{(3)} = (0.838, -0.157) * 0.7 * (0.237, 0.230) \\approx (0.139, -0.025)$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(2)}} = moy((0.139, -0.025) (0.622, 0.900)) \n",
    "= moy(0.086, -0.023) = 0.032$$\n",
    "\n",
    "---\n",
    "\n",
    "**Afin de mettre à jour** $w_{11}^{(2)}$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{11}^{(2)}} = \n",
    "\\overbrace{ \n",
    "\\left(\n",
    "\t\\delta_{1}^{(3)} \n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial z_{1}^{(3)}}{\\partial f_{1}^{(2)}}\n",
    "\t}^{w_{11}^{(3)}}\n",
    "\t+\n",
    "\t\\delta_{2}^{(3)} \n",
    "\t\\overbrace{\n",
    "\t\t\\frac{\\partial z_{2}^{(3)}}{\\partial f_{1}^{(2)}}\n",
    "\t}^{w_{12}^{(3)}}\n",
    "\\right)\n",
    "\\frac{\\partial f_{1}^{(2)}}{\\partial z_{1}^{(2)}}\n",
    "}^{\\delta_{1}^{(2)}} \n",
    "\\overbrace{\n",
    "\t\\frac{\\partial z_{1}^{(2)}}{\\partial w_{11}^{(2)}}\n",
    "}^{a_{1}^{(1)}}$$\n",
    "\n",
    "$$\\frac{\\partial f_{1}^{(2)}}{\\partial z_{1}^{(2)}} = (0.622, 0.900) (0.378, 0.100) = (0.235, 0.09)$$\n",
    "\n",
    "$$\\delta_{1}^{(2)} = \\left((0.145, -0.026) * (0.3) + (0.139, -0.025) * (-0.1)\\right) * (0.235, 0.09) \\approx (0.006956, -0.00047683)$$\n",
    "\n",
    "---\n",
    "\n",
    "**Cas general**\n",
    "\n",
    "On calcule les $\\delta^{(l)}$ où $l$ est le numéro de la couche\n",
    "\n",
    "$$\\delta^{(sortie)} = \n",
    "\\frac{\\partial J}{\\partial f^{(sortie)}} \\frac{\\partial f^{(sortie)}}{\\partial z^{(sortie)}}\n",
    "\\,,\\,\n",
    "\\delta^{(l)} = \\frac{\\partial f^{(l)}}{\\partial z^{(l)}} w^{(l+1)} \\delta^{(l+1)}$$\n",
    "\n",
    "On calcule les gradients\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w^{(l)}} = a^{(l-1)} \\delta^{(l)}\n",
    "\\,,\\,\n",
    "\\frac{\\partial J}{\\partial b^{(l)}} = \\delta^{(l)}$$\n",
    "\n",
    "On met à jour les paramètres\n",
    "\n",
    "$$w = w - \\alpha \\frac{\\partial J}{\\partial w^{(l)}}\n",
    "\\,,\\,\n",
    "b = b - \\alpha \\frac{\\partial J}{\\partial b^{(l)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.24.3', '2.0.3', '3.7.2')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy             as np\n",
    "import pandas            as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib      import colors \n",
    "%matplotlib inline\n",
    "\n",
    "np.__version__, pd.__version__, matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing          import Tuple, List, Type, Union\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Réalisation des algorithmes\n",
    "\n",
    "Ici, nous définissons un API (une sorte d'interfaces) pour les fonctions d'activation et les fonctions du cout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API (Ne modifier pas ; c'est juste une interface/classe abstraite)//dans le but de simuler comment les APIs (tenserflow,sickit learn)les implémentent\n",
    "class Activation(object): \n",
    "    # Calculer l'activation en se basant sur Z (la somme linéaire)\n",
    "    def activer(self, Z):\n",
    "        pass\n",
    "    # Calculer la dérivée en se basant sur Z et l'activation A\n",
    "    def deriver(self, Z, H):\n",
    "        pass\n",
    "\n",
    "# API (Ne modifier pas ; c'est juste une interface/classe abstraite)\n",
    "class Cout(object): \n",
    "    # Calculer l'activation en se basant sur Z (la somme linéaire)\n",
    "    def calculer(self, H, Y):\n",
    "        pass\n",
    "    # Calculer la dérivée en se basant sur Z et l'activation A\n",
    "    def deriver(self, H, Y):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Fonctions d'activation\n",
    "\n",
    "L'activation logistique est calculée comme :\n",
    "$$A = \\sigma(Z) = \\frac{1}{1+e^{-Z}}$$\n",
    "\n",
    "La dérivée partielle est donnée par :\n",
    "$$\\frac{\\partial \\sigma(Z)}{\\partial \\theta} = \\sigma(Z) (1-\\sigma(Z))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84104179, 0.84290453]), array([0.1336905 , 0.13241648]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Dérivée de la fonction d'activation logistique\n",
    "def d_sigmaf(Z, A): \n",
    "    return A*(1-A)\n",
    "\n",
    "# Rien à programmer ici\n",
    "def sigmaf(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "class Logistique(Activation):\n",
    "    def activer(self, Z):\n",
    "        return sigmaf(Z)\n",
    "    def deriver(self, Z, H):\n",
    "        return d_sigmaf(Z, H)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([0.84104179, 0.84290453]), array([0.1336905 , 0.13241648]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "logistique = Logistique()\n",
    "z4_1       = np.array([1.666, 1.68])\n",
    "a4_1       = logistique.activer(z4_1)\n",
    "a4_1p      = logistique.deriver(z4_1, a4_1)\n",
    "\n",
    "a4_1, a4_1p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Fonctions du coût\n",
    "\n",
    "La fonction BCE est calaculée par :\n",
    "$$BCE = - ( Y \\log(H) + (1-Y) \\log(1-H))$$\n",
    "\n",
    "Sa dérivée est calculée par :\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta} = \\frac{H-Y}{H - H^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.83258146, 0.17078832]), array([ 6.25      , -1.18623962]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Dérivée de la fonction d'erreur BCE\n",
    "def d_bcef(H, Y):\n",
    "    return (H-Y)/(H - H*H)\n",
    "\n",
    "def bcef(H, Y):\n",
    "    return - (Y * np.log(H) + (1-Y) * np.log(1-H))\n",
    "\n",
    "class BCE(Cout):\n",
    "    def calculer(self, H, Y):\n",
    "        return bcef(H, Y)\n",
    "    def deriver(self, H, Y):\n",
    "        return d_bcef(H, Y)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([1.83258146, 0.17078832]), array([ 6.25      , -1.18623962]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "bce = BCE()\n",
    "\n",
    "H = np.array([0.840 , 0.843])\n",
    "Y = np.array([0., 1.])\n",
    "J = bce.calculer(H, Y)\n",
    "DJ = bce.deriver(H, Y)\n",
    "\n",
    "J, DJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Neurone\n",
    "\n",
    "$$\\delta^{(l)} = \\frac{\\partial f^{(l)}}{\\partial z^{(l)}} w^{(l+1)} \\delta^{(l+1)}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w^{(l)}} = a^{(l-1)} \\delta^{(l)}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b^{(l)}} = \\delta^{(l)}$$\n",
    "\n",
    "Le produit est un produit matriciel (sur $M$) et il faut prendre la moyenne des sorties (sur $Ln$). \n",
    "\n",
    "La fonction qui met à jour les paramètres prend en entrée : \n",
    "- $W[Lp]$ une liste des poids; un vecteur de taille $Lp$ (le nombre des neurones de la couche précédente)\n",
    "- $b$ le biais \n",
    "- $Z[M]$ la combinaison linéaire du neurone courant; un vecteur de taille $M$ (le nombre des échantillons)\n",
    "- $A[M]$ l'activation du neurone courant; un vecteur de taille $M$  \n",
    "- $A\\_past[M, Lp]$ les activations des neurones de la couche précédente; une matrice de taille est $(M * Lp)$\n",
    "- $Delta\\_next[M, Ln]$ le delta calculé dans la couche suivante; une matrice de taille $M * Ln$ ($Ln$ : le nombre des neurones dans la couche suivante)\n",
    "- $W\\_next[Ln]$ les poids vers la couche suivante; un vecteur de taille $Ln$\n",
    "- $act$ c'est un object de type \"Activation\"; il fournit deux méthodes : \"act.activer\" et \"act.deriver\"\n",
    "- $alpha$ le pas de l'entraînement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49375218, 0.2046736 ]),\n",
       " -0.30324311474187016,\n",
       " array([ 0.00696306, -0.00047683]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Rétro-propagation (neurone)\n",
    "def neurone_maj(W, b, Z, A, A_past, Delta_next, W_next, act, alpha=1.):\n",
    "    Delta = act.deriver(Z, A) * np.dot(Delta_next, W_next)\n",
    "    bn    = b - alpha * np.mean(Delta,axis=0)\n",
    "    Wn    = W - alpha * np.dot(Delta.T, A_past)/len(A_past)\n",
    "    return Wn, bn, Delta\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([0.49375218, 0.2046736 ]),\n",
    "#  -0.30324311474187016,\n",
    "#  array([ 0.00696306, -0.00047683]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "W_t = np.array([0.5, 0.2])\n",
    "b_t = -0.3\n",
    "Z_t = np.array([0.5, 2.2])\n",
    "# M (l'activation actuelle)\n",
    "A_t = np.array([0.62245933, 0.90024951])\n",
    "# M * L (les activations de la couche précédente)\n",
    "A_past_t = np.array([[2., -1.], [3., 5.]])\n",
    "# L\n",
    "Delta_next_t = np.array([[ 0.14523862, -0.02613822], [ 0.1394202, -0.02531591]]).T\n",
    "W_next_t = np.array([0.3, -0.1])\n",
    "act = Logistique() #la fonction d'activation\n",
    "\n",
    "W_nouv, b_nouv, Delta_nouv = neurone_maj(W_t, b_t, Z_t, A_t, A_past_t, Delta_next_t, W_next_t, act, alpha=1.)\n",
    "\n",
    "W_nouv, b_nouv, Delta_nouv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z2_1 = [0.5 2.2]\n",
      "a2_1 = [0.62245933 0.90024951]\n",
      "derivee(a2_1) = [0.23500371 0.08980033]\n",
      "ancien b = -0.3\n",
      "ancien w = [0.5 0.2]\n",
      "delta2 = [ 0.00696306 -0.00047683]\n",
      "nouveaux b = -0.30324311473938026\n",
      "nouveaux w = [0.49375218 0.2046736 ]\n"
     ]
    }
   ],
   "source": [
    "class Neurone(object):\n",
    "    def __init__(self, taille_entree, activation=Logistique()):\n",
    "        self.b   = 0.\n",
    "        self.w   = np.array([0.] * taille_entree)\n",
    "        self.act = activation\n",
    "        \n",
    "    def randomiser(self):\n",
    "        self.w = np.random.rand(len(self.w))\n",
    "        self.b = np.random.rand(1)[0]\n",
    "        \n",
    "    def __aggreger(self, X):\n",
    "        return np.dot(X, self.w) + self.b\n",
    "    \n",
    "    def activer(self, X):\n",
    "        self.a_past = X\n",
    "        self.z      = self.__aggreger(X)\n",
    "        self.a      = self.act.activer(self.z)\n",
    "        return self.a\n",
    "    \n",
    "    def actualiser(self, delta_next, w_next, alpha=1.):\n",
    "        w_ancien              = self.w.copy()\n",
    "        self.w, self.b, delta = neurone_maj(self.w, self.b, self.z, self.a, self.a_past, \n",
    "                                            delta_next, w_next, self.act, alpha=alpha)\n",
    "        return delta, w_ancien\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# z2_1 = [0.5 2.2]\n",
    "# a2_1 = [0.62245933 0.90024951]\n",
    "# derivee(a2_1) = [0.23500371 0.08980033]\n",
    "# ancien b = -0.3\n",
    "# ancien w = [0.5 0.2]\n",
    "# delta2 = [ 0.00696306 -0.00047683]\n",
    "# nouveaux b = -0.30324311473938026\n",
    "# nouveaux w = [0.49375218 0.2046736 ]\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Céation d'un neurone avec deux entrées\n",
    "n = Neurone(2)\n",
    "# ---------------------\n",
    "#On ne doit pas affecter les poids directement \n",
    "#Ici, c'est juste pour avoir les mêmes poids du neurone de sortie dans l'exemple du cours\n",
    "# On va reproduire les paramètres du neurone 1 couche cachée 1 (couche 2)\n",
    "n.b = -0.3\n",
    "n.w = np.array([0.5, 0.2])\n",
    "# ---------------------\n",
    "\n",
    "# M X Lp (ici c'est X : couche d'entrée)\n",
    "A1 = np.array([[2., -1.], [3., 5.]])\n",
    "# M X Ln (Delta de la couche suivante)\n",
    "Delta3 = np.array([[ 0.14523862, -0.02613822], [ 0.1394202, -0.02531591]]).T\n",
    "W3_1 = np.array([0.3, -0.1])\n",
    "\n",
    "\n",
    "A2_1 = n.activer(A1)\n",
    "print(\"z2_1 = \" + str(n.z))\n",
    "print(\"a2_1 = \" + str(A2_1))\n",
    "# la dérivée de la fonction logistique n'a pas besoin de z, donc on passe 0\n",
    "print(\"derivee(a2_1) = \" + str(n.act.deriver(0,A2_1)))\n",
    "print(\"ancien b = \" + str(n.b))\n",
    "\n",
    "Delta2, W2_ancien = n.actualiser(Delta3, W3_1) \n",
    "\n",
    "print(\"ancien w = \" + str(W2_ancien))\n",
    "print(\"delta2 = \" + str(Delta2))\n",
    "print(\"nouveaux b = \" + str(n.b))\n",
    "print(\"nouveaux w = \" + str(n.w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Couche\n",
    "\n",
    "**Rien à programmer ici.**\n",
    "\n",
    "Une classe qui définit une couche en indiquant le nombre des neurones (taille), le nombre de ces entrées et la fonction d'activation de ces neurones.\n",
    "Cette classe comprend 3 méthodes : \n",
    "- randomiser : initialiser les paramètres des neurones d'une façon aléatoire\n",
    "- propagation_avant : appliquer la propagatation avant \n",
    "- retro_propagation : appliquer la rétropropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activations : [[0.62245933 0.66818777]\n",
      " [0.90024951 0.96770454]]\n",
      "deltas : [[ 0.00696306  0.00682726]\n",
      " [-0.00047683 -0.00017109]]\n"
     ]
    }
   ],
   "source": [
    "class Couche(object):\n",
    "    \n",
    "    def __init__(self, taille, taille_entree, activation=logistique):\n",
    "        self.neurones = [Neurone(taille_entree, activation=activation) for i in range(taille)]\n",
    "        \n",
    "    def randomiser(self):\n",
    "        for neurone in self.neurones:\n",
    "            neurone.randomiser()\n",
    "\n",
    "    def propagation_avant(self, X):\n",
    "        activations = []\n",
    "        for neurone in self.neurones:\n",
    "            activations.append(neurone.activer(X))\n",
    "        return np.array(activations).T\n",
    "    \n",
    "    def retro_propagation(self, delta_next, W_next, alpha=1.):\n",
    "        W_anciens = []\n",
    "        Deltas = []\n",
    "        for i, neurone in enumerate(self.neurones):\n",
    "            delta, w_ancien = neurone.actualiser(delta_next, W_next[i], alpha=alpha)\n",
    "            W_anciens.append(w_ancien)\n",
    "            Deltas.append(delta)\n",
    "        return np.array(Deltas).T, np.array(W_anciens).T\n",
    "\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# activations : [[0.62245933 0.66818777]\n",
    "#  [0.90024951 0.96770454]]\n",
    "# deltas : [[ 0.00696306  0.00682726]\n",
    "#  [-0.00047683 -0.00017109]]\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# la couche 2 \n",
    "c2 = Couche(2, 2)\n",
    "\n",
    "#On ne doit pas affecter les poids directement \n",
    "#Ici, c'est juste pour avoir les mêmes poids du neurone de sortie dans l'exemple du cours\n",
    "c2.neurones[0].b = -0.3\n",
    "c2.neurones[0].w = np.array([0.5, 0.2])\n",
    "c2.neurones[1].b = 0.5\n",
    "c2.neurones[1].w = np.array([0.3, 0.4])\n",
    "\n",
    "a2 = np.array([[2., -1.], [3., 5.]])\n",
    "# L\n",
    "delta3 = np.array([[ 0.14523862, -0.02613822], [ 0.1394202, -0.02531591]]).T\n",
    "w3 = np.array([[0.3, -0.1],[0.5, -0.3]])\n",
    "\n",
    "# M X Lp (ici c'est X : couche d'entrée)\n",
    "a1 = np.array([[2., -1.], [3., 5.]])\n",
    "a2 = c2.propagation_avant(a1)\n",
    "print(\"activations : \" + str(a2))\n",
    "\n",
    "Deltas2, W_anciens2 = c2.retro_propagation(delta3, w3)\n",
    "\n",
    "print(\"deltas : \" + str(Deltas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5. Réseau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le cout = 1.0020916974430962\n",
      "w4_1 = [0.51494626 0.56592079]\n",
      "w3_1 = [0.2665629 0.4641237]\n",
      "w3_2 = [-0.13199638 -0.33433028]\n",
      "w2_1 = [0.49375219 0.2046736 ]\n",
      "w2_2 = [0.29342937 0.40384135]\n",
      "la prédiction : [0 1]\n"
     ]
    }
   ],
   "source": [
    "class RN(object):\n",
    "    def __init__(self, taille_entree, cout=bce, alpha=1.):\n",
    "        self.taille_courante = taille_entree #la taille de la dernière couche\n",
    "        self.cout = cout #objet de type Cout pour calculer le cout et sa dérivée\n",
    "        self.alpha = alpha\n",
    "        self.couches = []\n",
    "\n",
    "    def ajouter_couche(self, taille, activation=logistique):\n",
    "        nouv_couche = Couche(taille, self.taille_courante, activation=activation)\n",
    "        self.couches.append(nouv_couche)\n",
    "        self.taille_courante = taille\n",
    "        \n",
    "    def randomiser(self):\n",
    "        for couche in self.couches:\n",
    "            couche.randomiser()\n",
    "    \n",
    "    def predire(self, X): \n",
    "        Y = X\n",
    "        if self.norm:\n",
    "            Y = np.where(self.std==0, X, (X - self.mean)/self.std)\n",
    "            \n",
    "        for couche in self.couches:\n",
    "            Y = couche.propagation_avant(Y)\n",
    "        if Y.ndim == 2 and Y.shape[1] == 1:\n",
    "            Y = Y.flatten()\n",
    "        return np.where(Y < 0.5, 0, 1)\n",
    "    \n",
    "    \n",
    "    def _faire_iteration(self, X, Y):\n",
    "        # propagation avant\n",
    "        a = X\n",
    "        for couche in self.couches:\n",
    "            a = couche.propagation_avant(a)\n",
    "            \n",
    "        # calcul du cout et sa dérivée \n",
    "        YY = np.array(Y)\n",
    "        if YY.ndim < 2 : \n",
    "            YY = YY[:, np.newaxis]\n",
    "        J = np.mean(self.cout.calculer(a, YY))\n",
    "        J_prime = self.cout.deriver(a, YY)\n",
    "        \n",
    "        # retropropagation \n",
    "        w_past = np.array([[1.] * self.taille_courante])\n",
    "        delta_past = J_prime\n",
    "        for couche in reversed(self.couches): # on commance de la dernière couche vers la première\n",
    "            delta_past, w_past = couche.retro_propagation(delta_past, w_past)\n",
    "        return J\n",
    "    \n",
    "    def entrainer(self, X, Y, nbr_it=100, norm=False):\n",
    "        couts = []\n",
    "        X_norm = X\n",
    "        self.norm = norm\n",
    "        if norm:\n",
    "            self.mean = np.mean(X, axis=0)\n",
    "            self.std = np.std(X, axis=0)\n",
    "            X_norm = np.where(self.std==0, X, (X - self.mean)/self.std)\n",
    "\n",
    "        for i in range(nbr_it): \n",
    "            J = self._faire_iteration(X_norm, Y)\n",
    "            couts.append(J)\n",
    "        return couts\n",
    "    \n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# le cout = 1.0020916974430965\n",
    "# w4_1 = [0.51494626 0.56592079]\n",
    "# w3_1 = [0.2665629 0.4641237]\n",
    "# w3_2 = [-0.13199638 -0.33433028]\n",
    "# w2_1 = [0.49375219 0.2046736 ]\n",
    "# w2_2 = [0.29342937 0.40384135]\n",
    "# la prédiction : [0 1]\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X = np.array([[2., -1.], [3., 5.]])\n",
    "Y = np.array([0., 1.])\n",
    "\n",
    "rn = RN(2) #deux caractéristiques d'entrée\n",
    "rn.ajouter_couche(2) #ajouter une couche avec 2 neurones (cachée)\n",
    "rn.ajouter_couche(2) #ajouter une couche avec 2 neurones (cachée)\n",
    "rn.ajouter_couche(1) #ajouter une couche avec 1 neurone (sortie)\n",
    "\n",
    "#On ne doit pas affecter les poids directement \n",
    "#Ici, c'est juste pour avoir les mêmes poids du neurone de sortie dans l'exemple du cours\n",
    "rn.couches[0].neurones[0].b = -0.3\n",
    "rn.couches[0].neurones[0].w = np.array([0.5, 0.2])\n",
    "rn.couches[0].neurones[1].b = 0.5\n",
    "rn.couches[0].neurones[1].w = np.array([0.3, 0.4])\n",
    "\n",
    "rn.couches[1].neurones[0].b = -0.3\n",
    "rn.couches[1].neurones[0].w = np.array([0.3, 0.5])\n",
    "rn.couches[1].neurones[1].b = -0.2\n",
    "rn.couches[1].neurones[1].w = np.array([-0.1, -0.3])\n",
    "\n",
    "rn.couches[2].neurones[0].b = 1.\n",
    "rn.couches[2].neurones[0].w = np.array([0.7, 0.7])\n",
    "\n",
    "J = rn._faire_iteration(X, Y)\n",
    "\n",
    "print(\"le cout = \" + str(J))\n",
    "print(\"w4_1 = \" + str(rn.couches[2].neurones[0].w))\n",
    "print(\"w3_1 = \" + str(rn.couches[1].neurones[0].w))\n",
    "print(\"w3_2 = \" + str(rn.couches[1].neurones[1].w))\n",
    "print(\"w2_1 = \" + str(rn.couches[0].neurones[0].w))\n",
    "print(\"w2_2 = \" + str(rn.couches[0].neurones[1].w))\n",
    "\n",
    "rn.entrainer(X, Y, nbr_it=200)\n",
    "print(\"la prédiction : \" + str(rn.predire(X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application et analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diabetes2\n",
    "diabetes   = pd.read_csv(\"D:\\\\Documents\\\\2CSSID\\\\myyear\\\\S1\\\\ML\\\\TP07SID\\\\data\\\\diabetes2.csv\") \n",
    "X_diabetes = diabetes.iloc[:, :-1].values  \n",
    "Y_diabetes = diabetes.iloc[:,  -1].values\n",
    "\n",
    "# Cette configuration est mise en place comme ceci exprès\n",
    "# C'est pour tester le cas où la régression est défavorisée\n",
    "NBR_TEST   = 240\n",
    "# Supposant que les 30% premières lignes sont pour le test et le reste pour l'entraînement\n",
    "X_test     = X_diabetes[-NBR_TEST:, :] # 30% ou plus\n",
    "Y_test     = Y_diabetes[-NBR_TEST:   ].reshape([-1, 1])\n",
    "\n",
    "X_train    = X_diabetes[:-NBR_TEST, :] \n",
    "Y_train    = Y_diabetes[:-NBR_TEST   ].reshape([-1, 1])\n",
    "\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63564802,  0.83833016,  0.16863427,  0.93506705, -0.67560188,\n",
       "         0.22006711,  0.42947843,  1.43582544],\n",
       "       [-0.85203884, -1.09137813, -0.14214721,  0.55085273, -0.67560188,\n",
       "        -0.63225191, -0.38057337, -0.18535642],\n",
       "       [ 1.23072277,  1.91039032, -0.24574104, -1.30618316, -0.67560188,\n",
       "        -1.03405944,  0.56155209, -0.10003106],\n",
       "       [-0.85203884, -0.96885697, -0.14214721,  0.16663841,  0.12145706,\n",
       "        -0.44961212, -0.92060791, -1.03861003],\n",
       "       [-1.14957621,  0.50139697, -1.48886696,  0.93506705,  0.74892899,\n",
       "         1.37678577,  5.30446409, -0.0147057 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler   = StandardScaler()\n",
    "X_trains = scaler.fit_transform(X_train)\n",
    "X_tests  = scaler.transform(X_test)\n",
    "\n",
    "X_trains[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1. Paramètres initiaux et complexité\n",
    "\n",
    "Nous voulons tester l'intêt de l'initialisation des paramètres (thétas) et la complexité du modèle.\n",
    "Pour ce faire, cinq modèles ont été entrainés afin de récupérer l'erreur d'entrainement et de la validation. \n",
    "Les modèles testé sont :\n",
    "- **Log0** : Un seul neurone (régression logistique) avec initialisation 0\n",
    "- **LogR** : Un seul neurone (régression logistique) avec initialisation aléatoire\n",
    "- **RN0** : Un réseau de neurones 4(relu)X2(relu)X1(sigmoid) avec initialisation 0\n",
    "- **RN1** : Un réseau de neurones 4(relu)X2(relu)X1(sigmoid) avec initialisation 1\n",
    "- **RNR** : Un réseau de neurones 4(relu)X2(relu)X1(sigmoid) avec initialisation aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m logging\u001b[38;5;241m.\u001b[39mdisable(logging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m              \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow              import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "alpha  = 0.01\n",
    "NBR_IT = 200\n",
    "\n",
    "M, N = X_train.shape\n",
    "\n",
    "# ==================================\n",
    "# Définition des modèles\n",
    "# ==================================\n",
    "\n",
    "modeles = {}\n",
    "\n",
    "modeles['Log0'] = Sequential()\n",
    "modeles['Log0'].add(Dense(1, activation=\"sigmoid\", kernel_initializer='zero', bias_initializer='zeros'))\n",
    "\n",
    "modeles['LogR'] = Sequential()\n",
    "modeles['LogR'].add(Dense(1, activation=\"sigmoid\", kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform'))\n",
    "\n",
    "modeles['RN0']  = Sequential()\n",
    "modeles['RN0'].add(Dense(4, activation=\"relu\", kernel_initializer='zero', bias_initializer='zeros'))\n",
    "modeles['RN0'].add(Dense(2, activation=\"relu\", kernel_initializer='zero', bias_initializer='zeros'))\n",
    "modeles['RN0'].add(Dense(1, activation=\"sigmoid\", kernel_initializer='zero', bias_initializer='zeros'))\n",
    "\n",
    "modeles['RN1']  = Sequential()\n",
    "modeles['RN1'].add(Dense(4, activation=\"relu\", kernel_initializer='one', bias_initializer='one'))\n",
    "modeles['RN1'].add(Dense(2, activation=\"relu\", kernel_initializer='one', bias_initializer='one'))\n",
    "modeles['RN1'].add(Dense(1, activation=\"sigmoid\", kernel_initializer='one', bias_initializer='one'))\n",
    "\n",
    "modeles['RNR']  = Sequential()\n",
    "modeles['RNR'].add(Dense(4, activation=\"relu\", kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform'))\n",
    "modeles['RNR'].add(Dense(2, activation=\"relu\", kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform'))\n",
    "modeles['RNR'].add(Dense(1, activation=\"sigmoid\", kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform'))\n",
    "\n",
    "# ==================================\n",
    "# Entrainement des modèles\n",
    "# ==================================\n",
    "\n",
    "# on n'affiche pas les 3 premières itérations, le temps que le modèle se stabilise\n",
    "# sinon, un modèle peut avoir une grande valeur par rapport aux autres \n",
    "# donc, on ne peut pas visualiser la convergence des autres\n",
    "IT_range = range(NBR_IT)[3:]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "\n",
    "for nom, modele in modeles.items():\n",
    "    modele.compile(loss      = tf.keras.losses.binary_crossentropy,\n",
    "                 optimizer = tf.keras.optimizers.SGD(learning_rate=alpha))\n",
    "    print(nom, ': Entrainement ...')\n",
    "    results = modele.fit(X_trains, Y_train, epochs=NBR_IT, validation_data=(X_tests, Y_test), verbose=0)\n",
    "    \n",
    "    # ===========================\n",
    "    # PREPARATION DE L'AFFICHAGE\n",
    "    # ===========================\n",
    "    ax1.plot(IT_range, results.history[\"loss\"    ][3:], label=nom)\n",
    "    ax2.plot(IT_range, results.history[\"val_loss\"][3:], label=nom)\n",
    "\n",
    "# ==================================\n",
    "# Affichage \n",
    "# ==================================\n",
    "\n",
    "ax1.title.set_text(\"Entrainement\")\n",
    "ax2.title.set_text(\"Validation\")\n",
    "\n",
    "ax1.set(xlabel='iteration', ylabel='erreur')\n",
    "ax2.set(xlabel='iteration', ylabel='erreur')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "- Nous remarquons que les modèles avec un seul neurone sont plus rapides que les modèles de réseau de neurones (en terme des itérations et en terme de temps). Pourquoi ?\n",
    "- Nous remarquons que **RN0** ne s'améliore pas (il stagne dès les premières itérations). Expliquer pourquoi.\n",
    "- Nous remarquons que **RN1** s'améliore par rapport à **RN0**, mais il stagne rapidement par rapport **RNR**. Expliquer pourquoi.expliquer à travers les formules mathématiques.\n",
    "- En se basant sur la validation, quelle est le rapport entre le nombre des couches, la complexité du problème, le nombre/qualité des données et les problèmes d'apprentissage (sous/sur). Mentionner toutes les combinaisons qui peuvent causer des problèmes. 4 combinaisons\n",
    "\n",
    "\n",
    "**Réponse**\n",
    "- Les modèles avec un seul neurones sont plus rapides car ils sont moins complexes et donc necessitent le reajustement de moins de paramètres que ceux avec plusieurs neurones (ainsi que le calcul de moins de derivées moins) et aussi pour la validation, la validation sur un seul neurone est bien plus rapide que sur plusieurs couches de plusieurs neurones car il y a moins de calculs à effectuer.\n",
    "- l'initialisation des paramétres du RN a zero : tous les poids sont à 0 ça veut dire que tous les paramétres vont recevoir la méme mise à jour pendant la phase de retropropagation , en d'autre terme tous les paramétres vont apprendre la méme information et du coup durant l'operation de mise à jour ils vont tous étre proches et petits dans chaque itération , ce qui cause finalement la stagnation rapide du modéle mais dans une valeur qui est loin de la valeur optimale des paramétres et donc une mauvaise performance du modèle (sous-apprentissage).\n",
    "- Pour RN1, l'initialisation de tous les paramètres à 1 évite que la dérivée partielle par rapport aux poids soit nulle mais elle reste relativement petite et donc les mise à jour des paramètres restent petites et se font aussi de la meme façon pour tous les paramètres donc malgré l'introduction d'une différence par rapport à l'initialisation à 0 mais le fait que tous les paramètres reçoivent la meme valeur garde toujours le problème de symétrie de ces dernier et fait que le modèle stagne assez rapidement par contre l'initialisation aléatoire assure que les paramètres soient diversifiés et donc chaque paramètres évoluera seul independemmet des autres ce qui permet de capturer plus d'informations et que le modèle ne stagne pas.\n",
    "- 1 - un probleme complexe ,un reseau de neurones avec plusieurs couches de plusieurs neurones avec un nombre petit d'observations dans le dataset --> le nombre des observations ne suffit pas pour mise a jourer les paramétres(sous apprentissage). \n",
    "- 2 - un probléme simple avec un grand nombre de couches et un dataset dont les observations sont d'une distribution similaire (pas de variété) --> surapprentissage.\n",
    "- 3 - un probléme complexe (ou simple) avec un nombre réduit des couches et peu de données (sous apprentissage).\n",
    "- 4 - peu importe la complexité du modèle ou du problème si les données sont de mauvaise qualités elles ne pourront pas refléter la nature du problème et donc on aura un modèle qui n'est pas accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2. Fonctions d'activation\n",
    "\n",
    "Nous voulons tester quelles sont les fonctions d'activation plus adéquates aux couches cachées et celles à la couche de sortie.\n",
    "Pour ce faire, cinq modèles ont été entrainés afin de récupérer l'historique de l'erreur d'entrainement. \n",
    "Les modèles testé sont :\n",
    "- **relu->sigm** : un réseau avec **relu** dans les couches cachées et **sigmoid** dans la couche de sortie\n",
    "- **sigm->sigm** : un réseau avec **sigmoid** dans les couches cachées et **sigmoid** dans la couche de sortie\n",
    "- **tanh->sigm** : un réseau avec **tanh** dans les couches cachées et **sigmoid** dans la couche de sortie\n",
    "- **sigm->relu** : un réseau avec **sigmoid** dans les couches cachées et **relu** dans la couche de sortie\n",
    "- **relu->relu** : un réseau avec **relu** dans les couches cachées et **relu** dans la couche de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu->sigm : Entrainement ...\n",
      "sigm->sigm : Entrainement ...\n",
      "tanh->sigm : Entrainement ...\n",
      "sigm->relu : Entrainement ...\n",
      "relu->relu : Entrainement ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha  = 0.01\n",
    "NBR_IT = 100\n",
    "\n",
    "M, N = X_train.shape\n",
    "\n",
    "L1 = 2 # Nombre des neurones dans la couche 1\n",
    "L2 = 2 # Nombre des neurones dans la couche 2\n",
    "\n",
    "# ==================================\n",
    "# Définition des modèles\n",
    "# ==================================\n",
    "\n",
    "defs = [ # Les définitions\n",
    "    ('relu->sigm', 'relu', 'sigmoid'),\n",
    "    ('sigm->sigm', 'sigmoid', 'sigmoid'),\n",
    "    ('tanh->sigm', 'tanh', 'sigmoid'),\n",
    "    ('sigm->relu', 'sigmoid', 'relu'),\n",
    "    ('relu->relu', 'relu', 'relu')\n",
    "]\n",
    "\n",
    "modeles = {}\n",
    "params = {'kernel_initializer':'glorot_uniform', 'bias_initializer':'glorot_uniform'}\n",
    "\n",
    "for nom, in_act, out_act in defs:\n",
    "    modeles[nom] = Sequential()\n",
    "    modeles[nom].add(Dense(L1, activation = in_act , **params))\n",
    "    modeles[nom].add(Dense(L2, activation = in_act , **params))\n",
    "    modeles[nom].add(Dense(1,  activation = out_act, **params))\n",
    "\n",
    "# ==================================\n",
    "# Entrainement des modèles\n",
    "# ==================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "for nom, modele in modeles.items():\n",
    "    modele.compile(loss      = tf.keras.losses.binary_crossentropy,\n",
    "                 optimizer = tf.keras.optimizers.SGD(learning_rate=alpha))\n",
    "    print(nom, ': Entrainement ...')\n",
    "    results[nom] = modele.fit(X_trains, Y_train, epochs=NBR_IT, verbose=0)\n",
    "    \n",
    "\n",
    "# ==================================\n",
    "# Affichage \n",
    "# ==================================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "for nom, result in results.items():\n",
    "    ax = ax1 if nom.endswith('sigm') else ax2\n",
    "    ax.plot(range(NBR_IT), result.history['loss'], label=nom)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"erreur\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "- Nous remarquons que le modèle **sigmoid->sigmoid** a stagné rapidement. Expliquer comment ?\n",
    "- Nous remarquons que ce modèle a convergé plus rapidement (en terme de nombre des itérations) par rapport aux deux modèles avec sortie **sigmoid**. Pourquoi ?\n",
    "- Nous remarquons que les modèles avec sortie **relu** ne sont pas stables ; à chaque exécution, nous aurons un diagramme différent (des fois amélioration, des fois détérioration, etc.). Il faut noter que l'initialisation aléatoire n'est pas la source du problème vu qu'il y a d'autres modèles similaires mais stables. Donc, pourquoi nous avons eu ce comportement ?\n",
    "\n",
    "**Réponse**\n",
    "- les valeurs d'entrée de la sigmoid sont très grandes et sachant que les sorties de la sigmoid seront très petites (prend des valeurs entre 0 et 1) et cela fera que la mise à jour de chaque paramètre du modèle se fait juste par une petite modification autrement dit il y a une réduction de l'information ce qui affecte l'opération de rétropropagation et par conséquent une stagnation rapide du modèle.\n",
    "- Ceci est du au fait que les deux autres ont utiliser les fonctions relu et tanh pour l'activation ce qui a aider a augmenter la variétés des valeurs par rapport a celle de segmoid-->segmoid car relu retourne le x s'il est positif et la tanh a une plage supérieure aussi à celle de la sigmoid qui de -1 à 1.\n",
    "- Ceci peut etre du aux données vu que la fonction relu retourne l'entrée donc pour le modèle ou on utilise exlusivement le relu il y de très grandes oscillation (grande influence des données ) par contre pour celui ou il y a la sigmoid il converge plus rapidement (la sigmoid aténue les données et donne des paramètres relativement plus petits donc qui peuvent se stabiliser rapidement), en général vu que les valeurs de sortie de reLu sont grandes le modèle risque donc de diverger pour un taux d'apprentissage trop grand ou mal choisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3. Fonctions d'optimisation\n",
    "\n",
    "Nous voulons tester des différentes fonctions d'optimisation.\n",
    "Pour ce faire, quatres modèles ont été entrainés afin de récupérer l'historique de l'erreur d'entrainement. \n",
    "Les modèles testés sont :\n",
    "- **GD** : un réseau entrainé avec la descente des gradients\n",
    "- **Adagrad** : un réseau entrainé avec AdaGrad\n",
    "- **RMSprop** : un réseau entrainé avec RMSprop\n",
    "- **Adam** : un réseau entrainé avec Adam\n",
    "\n",
    "**Chercher sur Internet les formules de chacune de ces fonctions d'optimisation afin de pouvoir repondre aux questions suivantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# on n'affiche pas les 3 premières itérations, le temps que le modèle se stabilise\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# sinon, un modèle peut avoir une grande valeur par rapport aux autres \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# donc, on ne peut pas visualiser la convergence des autres\u001b[39;00m\n\u001b[0;32m     12\u001b[0m IT_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(NBR_IT)[\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m     14\u001b[0m defs \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;66;03m# Les définitions\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGD\u001b[39m\u001b[38;5;124m'\u001b[39m     , tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD    (learning_rate\u001b[38;5;241m=\u001b[39malpha)),\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdagrad\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39malpha)),\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSprop\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRMSprop(learning_rate\u001b[38;5;241m=\u001b[39malpha)),\n\u001b[0;32m     18\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m   , tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam   (learning_rate\u001b[38;5;241m=\u001b[39malpha))\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_initializer\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias_initializer\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nom, opt \u001b[38;5;129;01min\u001b[39;00m defs:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "alpha  = 0.01\n",
    "NBR_IT = 300\n",
    "\n",
    "M, N = X_train.shape\n",
    "\n",
    "L1 = 2\n",
    "L2 = 2\n",
    "\n",
    "# on n'affiche pas les 3 premières itérations, le temps que le modèle se stabilise\n",
    "# sinon, un modèle peut avoir une grande valeur par rapport aux autres \n",
    "# donc, on ne peut pas visualiser la convergence des autres\n",
    "IT_range = range(NBR_IT)[3:]\n",
    "\n",
    "defs = [ # Les définitions\n",
    "    ('GD'     , tf.keras.optimizers.SGD    (learning_rate=alpha)),\n",
    "    ('Adagrad', tf.keras.optimizers.Adagrad(learning_rate=alpha)),\n",
    "    ('RMSprop', tf.keras.optimizers.RMSprop(learning_rate=alpha)),\n",
    "    ('Adam'   , tf.keras.optimizers.Adam   (learning_rate=alpha))\n",
    "]\n",
    "\n",
    "params = {'kernel_initializer':'glorot_uniform', 'bias_initializer':'glorot_uniform'}\n",
    "\n",
    "for nom, opt in defs:\n",
    "    modele = Sequential()\n",
    "    modele.add(Dense(L1, activation=\"relu\"   , **params))\n",
    "    modele.add(Dense(L2, activation=\"relu\"   , **params))\n",
    "    modele.add(Dense(1,  activation=\"sigmoid\", **params))\n",
    "    modele.compile(loss      = tf.keras.losses.binary_crossentropy,\n",
    "                   optimizer = opt)\n",
    "    \n",
    "    print(nom, ': entrainement ...')\n",
    "    results = modele.fit(X_trains, Y_train, epochs=NBR_IT, verbose=0)\n",
    "    plt.plot(IT_range, results.history[\"loss\"][3:], label=nom)\n",
    "\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"erreur\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyser les résultats**\n",
    "- Nous remarquons que le modèle **GD** converge plus vite que **AdaGrad**. Pourquoi ?\n",
    "- Pourquoi **RMSprop** converge plus vite que **AdaGrad**, pourtant leurs equations sont presque similaire ? (ici, vous devez expliquer l'apport dans l'equation du premier par rapport au deuxième)\n",
    "- En exécutant ce code plusieurs fois, nous remarquons que Adam est plus stable. Pourquoi ?\n",
    "\n",
    "**Réponse**\n",
    "- Le modèle GD converge plus par rapport à AdaGrad à cause de l'effet que la somme des carrés des gradients sur le taux d'apprentissage, la fait de mettre tous les gradients au carré augmente leur effet, donc en divisant le taux d'apprentissage sur la racine de la somme de ce derniers diminue considérablement le taux d'apprentissage adaptatif et donc entraine la convergence lente du modèle ADAGrad par rapport au GD simple.\n",
    "- En analysant les équations des deux algorithmes (ADAGrad--> **θₜ₊₁ = θₜ - η / (√(Gₜ + ε)) * ∇J(θₜ)** et RMSprop--> **θₜ₊₁ = θₜ - η / √(E[g²]ₜ + ε) * ∇J(θₜ)** et **E[g²]ₜ = β E[g²]ₜ₋₁ + (1 - β) (∇J(θₜ))²**) on peut remarquer que l'algorithme RMSprop utilise une somme pondérée des gradients donc le fait de multiplier par le coefficient beta qui est proche de 1 (et 1-beta pour le gradient de l'iteration actuelle) rend les valeurs plus petites que celle qu'on obtient avec AdaGrad et donc on obtient un taux d'apprentissage plus élevé et donc le RMSprop converge mieux en moins d'itérations que AdaGrad(pour le RMSprop on a l'attenuation de l'effet des carrés par rapport à AdaGrad).\n",
    "- En analysant les équations de l'algorithme d'Adam, on peut dire que l'utilisation de la méthode des moments garantie qu'il n'y est pas une grande différence (grand saut) entre les valeurs des paramètres à chaque itération et donc ceci garantie moins d'oscillations et plus de stabilité lors de la convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
